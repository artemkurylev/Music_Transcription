{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in to Weights & Biases!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\130/.netrc\n"
     ]
    }
   ],
   "source": [
    "from comet_ml import Experiment\n",
    "import numpy as np\n",
    "import argparse\n",
    "from scipy import signal\n",
    "from midiutil.MidiFile import MIDIFile\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile\n",
    "import librosa\n",
    "import csv\n",
    "import time\n",
    "import h5py\n",
    "import pickle\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "from Repository.utils import constant\n",
    "from sklearn import metrics as sk_metrics\n",
    "from joblib import Parallel, delayed\n",
    "from librosa import display\n",
    "from librosa.display import specshow\n",
    "from sklearn.metrics import classification_report, roc_curve, auc\n",
    "from Repository.models.model import ANN\n",
    "from Repository.utils.utils import DataProcessor\n",
    "import wandb\n",
    "!wandb login a357c1b1a853443058bbe237eaba6a07f8e928a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_file_search(folder):\n",
    "    files = [os.path.join(folder, file) for file in os.listdir(folder) if os.path.isfile(os.path.join(folder, file))]\n",
    "    folders = [os.path.join(folder, file) for file in os.listdir(folder) if os.path.isdir(os.path.join(folder, file))]\n",
    "    if folders:\n",
    "        for next_folder in folders:\n",
    "            files.extend(recursive_file_search(next_folder))\n",
    "\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'MAPS/MAPS1/SptkBGAm/SptkBGAm/ISOL/CH/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataProcessor(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.load_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    3.1s remaining:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:    4.3s remaining:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    4.4s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    9.2s finished\n"
     ]
    }
   ],
   "source": [
    "dp.load_audios(sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "dp.generate_cqts()\n",
    "X,y = dp.get_cqt_data(from_file=False,cnn=True)\n",
    "#dp.process_audios(from_file=False)\n",
    "#X,y = dp.get_cfp_data(from_file=False,cnn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((X.shape[0], X.shape[3],X.shape[2],X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "X_train = torch.from_numpy(np.array(X_train))\n",
    "X_test = torch.from_numpy(np.array(X_test))\n",
    "\n",
    "temp_train = []\n",
    "temp_test = []\n",
    "for i in y_train:\n",
    "    temp_train.append(i)\n",
    "for i in y_test:\n",
    "    temp_test.append(i)\n",
    "\n",
    "y_train = torch.tensor(temp_train)\n",
    "y_test = torch.tensor(temp_test)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train.float(), y_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test.float(), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "batch_size = 200\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing model\n",
    "def test( class_predictor, device, test_loader):\n",
    "    class_predictor.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            labels = target\n",
    "            target =  labels.clone().detach().squeeze().to(device).long()\n",
    "            output = model(data.float())\n",
    "\n",
    "            correct += torch.round(torch.sigmoid(output)).eq(target).sum().item()\n",
    "    return 100. * correct / (len(test_loader.dataset) * 88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_accuracy(results, target):\n",
    "    correct = np.zeros(len(results[0]))\n",
    "    correct = np.add(correct,torch.eq(results,target).sum(dim=0).detach().cpu().numpy())\n",
    "    correct /= len(results)\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(class_predictor,device,test_loader,threshold=0.5):\n",
    "    class_predictor.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    all_predicted = []\n",
    "    predicted_probs = []\n",
    "    one = torch.ones(1).to(device)\n",
    "    zero = torch.zeros(1).to(device)\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            labels = target\n",
    "            target = labels.clone().detach().squeeze().to(device).long()\n",
    "            output = class_predictor(data.float())\n",
    "            predicted = torch.where(torch.sigmoid(output)>threshold,one,zero).cpu().data.numpy().tolist()\n",
    "            predicted_probs.extend(torch.sigmoid(output).detach().cpu().numpy().tolist())\n",
    "            all_predicted.extend(predicted)\n",
    "    return all_predicted,predicted_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_f_score(class_predictor,device,test_loader,y_true,threshold=0.5, average='micro'):\n",
    "    predictions, probs = eval(class_predictor,device,test_loader,threshold)\n",
    "    predictions = np.array(predictions)\n",
    "    y_true = y_true.numpy()\n",
    "    score = sk_metrics.f1_score(y_true,predictions,average=average)\n",
    "    acc = sk_metrics.accuracy_score(y_true,predictions)\n",
    "    pr = sk_metrics.precision_score(y_true,predictions,average=average)\n",
    "    rec = sk_metrics.recall_score(y_true,predictions,average=average)\n",
    "    return score,acc, pr, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1,32,(5,3)),\n",
    "            nn.SELU(),\n",
    "            nn.Conv2d(32,32,(1,3)),\n",
    "            nn.SELU(),\n",
    "            nn.MaxPool2d((2,1)),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(32*40,512),\n",
    "            nn.SELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512,512),\n",
    "            nn.SELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512,88),\n",
    "        )\n",
    "        self.out = nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        res = self.conv1(x)\n",
    "        res = res.view(-1,32*40)\n",
    "        res = self.fc1(res)\n",
    "        #res = self.out(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(550,512),\n",
    "            nn.SELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512,512),\n",
    "            nn.SELU(),\n",
    "            nn.Dropout(0.5), \n",
    "            nn.Linear(512,88),\n",
    "        )\n",
    "        self.out = nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        res = x.view(-1,550)\n",
    "        res = self.fc1(res)\n",
    "        \n",
    "        res = self.out(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.normal_(m.weight,0.0,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)#ANN(257,nn.SELU(),107).to(device)\n",
    "model.conv1.apply(init_weights)\n",
    "model.fc1.apply(init_weights)\n",
    "pos_weight = torch.Tensor([50]*88).to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Engine, _prepare_batch\n",
    "criterion = nn.BCELoss(reduction='mean')\n",
    "def process_function(engine, batch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x, y = _prepare_batch(batch, device=device)\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "trainer = Engine(process_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Events\n",
    "\n",
    "log_interval = 200\n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def log_training_loss(engine):\n",
    "    iteration = (engine.state.iteration - 1) % len(train_loader) + 1\n",
    "    if iteration % log_interval == 0:\n",
    "        print(\"Epoch[{}] Iteration[{}/{}] Loss: {:.4f}\"\n",
    "              .format(engine.state.epoch, \n",
    "                         iteration, \n",
    "                         len(train_loader), \n",
    "                         engine.state.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 96.95037105751393 on train_dataset \n",
      "\n",
      "Train Epoch: 50 [0/1375 (0%)]\tLoss: 0.303600\n",
      "Accuracy is 96.56679035250463 on train_dataset \n",
      "\n",
      "Train Epoch: 51 [0/1375 (0%)]\tLoss: 0.280799\n",
      "Accuracy is 96.50823283858998 on train_dataset \n",
      "\n",
      "Train Epoch: 52 [0/1375 (0%)]\tLoss: 0.287153\n",
      "Accuracy is 96.5211038961039 on train_dataset \n",
      "\n",
      "Train Epoch: 53 [0/1375 (0%)]\tLoss: 0.287761\n",
      "Accuracy is 96.81238404452691 on train_dataset \n",
      "\n",
      "Train Epoch: 54 [0/1375 (0%)]\tLoss: 0.285786\n",
      "Accuracy is 96.54510667903526 on train_dataset \n",
      "\n",
      "Train Epoch: 55 [0/1375 (0%)]\tLoss: 0.299776\n",
      "Accuracy is 96.5332792207792 on train_dataset \n",
      "\n",
      "Train Epoch: 56 [0/1375 (0%)]\tLoss: 0.284822\n",
      "Accuracy is 96.9383116883117 on train_dataset \n",
      "\n",
      "Train Epoch: 57 [0/1375 (0%)]\tLoss: 0.278449\n",
      "Accuracy is 96.97251855287571 on train_dataset \n",
      "\n",
      "Train Epoch: 58 [0/1375 (0%)]\tLoss: 0.283673\n",
      "Accuracy is 96.3964517625232 on train_dataset \n",
      "\n",
      "Train Epoch: 59 [0/1375 (0%)]\tLoss: 0.277166\n",
      "Accuracy is 96.41175788497218 on train_dataset \n",
      "\n",
      "Train Epoch: 60 [0/1375 (0%)]\tLoss: 0.260210\n",
      "Accuracy is 96.5060296846011 on train_dataset \n",
      "\n",
      "Train Epoch: 61 [0/1375 (0%)]\tLoss: 0.266308\n",
      "Accuracy is 96.6185064935065 on train_dataset \n",
      "\n",
      "Train Epoch: 62 [0/1375 (0%)]\tLoss: 0.271470\n",
      "Accuracy is 96.90711966604823 on train_dataset \n",
      "\n",
      "Train Epoch: 63 [0/1375 (0%)]\tLoss: 0.287034\n",
      "Accuracy is 96.79313543599257 on train_dataset \n",
      "\n",
      "Train Epoch: 64 [0/1375 (0%)]\tLoss: 0.265962\n",
      "Accuracy is 96.92300556586271 on train_dataset \n",
      "\n",
      "Train Epoch: 65 [0/1375 (0%)]\tLoss: 0.270553\n",
      "Accuracy is 96.8262987012987 on train_dataset \n",
      "\n",
      "Train Epoch: 66 [0/1375 (0%)]\tLoss: 0.244700\n",
      "Accuracy is 96.71660482374767 on train_dataset \n",
      "\n",
      "Train Epoch: 67 [0/1375 (0%)]\tLoss: 0.259235\n",
      "Accuracy is 96.8047309833024 on train_dataset \n",
      "\n",
      "Train Epoch: 68 [0/1375 (0%)]\tLoss: 0.263069\n",
      "Accuracy is 97.03339517625231 on train_dataset \n",
      "\n",
      "Train Epoch: 69 [0/1375 (0%)]\tLoss: 0.249901\n",
      "Accuracy is 96.63961038961038 on train_dataset \n",
      "\n",
      "Train Epoch: 70 [0/1375 (0%)]\tLoss: 0.260871\n",
      "Accuracy is 96.74942022263451 on train_dataset \n",
      "\n",
      "Train Epoch: 71 [0/1375 (0%)]\tLoss: 0.239879\n",
      "Accuracy is 96.83824211502784 on train_dataset \n",
      "\n",
      "Train Epoch: 72 [0/1375 (0%)]\tLoss: 0.258331\n",
      "Accuracy is 96.94561688311688 on train_dataset \n",
      "\n",
      "Train Epoch: 73 [0/1375 (0%)]\tLoss: 0.239201\n",
      "Accuracy is 97.0069573283859 on train_dataset \n",
      "\n",
      "Train Epoch: 74 [0/1375 (0%)]\tLoss: 0.243167\n",
      "Accuracy is 96.88300092764379 on train_dataset \n",
      "\n",
      "Train Epoch: 75 [0/1375 (0%)]\tLoss: 0.243837\n",
      "Accuracy is 97.10018552875695 on train_dataset \n",
      "\n",
      "Train Epoch: 76 [0/1375 (0%)]\tLoss: 0.248538\n",
      "Accuracy is 96.82339981447124 on train_dataset \n",
      "\n",
      "Train Epoch: 77 [0/1375 (0%)]\tLoss: 0.243832\n",
      "Accuracy is 96.78374304267162 on train_dataset \n",
      "\n",
      "Train Epoch: 78 [0/1375 (0%)]\tLoss: 0.233299\n",
      "Accuracy is 96.96011131725417 on train_dataset \n",
      "\n",
      "Train Epoch: 79 [0/1375 (0%)]\tLoss: 0.245192\n",
      "Accuracy is 96.93738404452688 on train_dataset \n",
      "\n",
      "Train Epoch: 80 [0/1375 (0%)]\tLoss: 0.232712\n",
      "Accuracy is 96.97333024118738 on train_dataset \n",
      "\n",
      "Train Epoch: 81 [0/1375 (0%)]\tLoss: 0.240366\n",
      "Accuracy is 97.10030148423004 on train_dataset \n",
      "\n",
      "Train Epoch: 82 [0/1375 (0%)]\tLoss: 0.240609\n",
      "Accuracy is 96.90317717996291 on train_dataset \n",
      "\n",
      "Train Epoch: 83 [0/1375 (0%)]\tLoss: 0.230757\n",
      "Accuracy is 96.7760899814471 on train_dataset \n",
      "\n",
      "Train Epoch: 84 [0/1375 (0%)]\tLoss: 0.232406\n",
      "Accuracy is 97.00336270871985 on train_dataset \n",
      "\n",
      "Train Epoch: 85 [0/1375 (0%)]\tLoss: 0.225729\n",
      "Accuracy is 96.64691558441557 on train_dataset \n",
      "\n",
      "Train Epoch: 86 [0/1375 (0%)]\tLoss: 0.250399\n",
      "Accuracy is 96.88995825602969 on train_dataset \n",
      "\n",
      "Train Epoch: 87 [0/1375 (0%)]\tLoss: 0.214660\n",
      "Accuracy is 97.09195269016698 on train_dataset \n",
      "\n",
      "Train Epoch: 88 [0/1375 (0%)]\tLoss: 0.224160\n",
      "Accuracy is 97.0831400742115 on train_dataset \n",
      "\n",
      "Train Epoch: 89 [0/1375 (0%)]\tLoss: 0.227412\n",
      "Accuracy is 97.00718923933209 on train_dataset \n",
      "\n",
      "Train Epoch: 90 [0/1375 (0%)]\tLoss: 0.217413\n",
      "Accuracy is 97.14552411873841 on train_dataset \n",
      "\n",
      "Train Epoch: 91 [0/1375 (0%)]\tLoss: 0.229444\n",
      "Accuracy is 96.75753710575138 on train_dataset \n",
      "\n",
      "Train Epoch: 92 [0/1375 (0%)]\tLoss: 0.250291\n",
      "Accuracy is 96.82873376623377 on train_dataset \n",
      "\n",
      "Train Epoch: 93 [0/1375 (0%)]\tLoss: 0.224701\n",
      "Accuracy is 97.11873840445267 on train_dataset \n",
      "\n",
      "Train Epoch: 94 [0/1375 (0%)]\tLoss: 0.213655\n",
      "Accuracy is 96.98538961038963 on train_dataset \n",
      "\n",
      "Train Epoch: 95 [0/1375 (0%)]\tLoss: 0.212739\n",
      "Accuracy is 96.99304267161409 on train_dataset \n",
      "\n",
      "Train Epoch: 96 [0/1375 (0%)]\tLoss: 0.209425\n",
      "Accuracy is 96.86375231910947 on train_dataset \n",
      "\n",
      "Train Epoch: 97 [0/1375 (0%)]\tLoss: 0.211547\n",
      "Accuracy is 97.14575602968462 on train_dataset \n",
      "\n",
      "Train Epoch: 98 [0/1375 (0%)]\tLoss: 0.205633\n",
      "Accuracy is 97.1318413729128 on train_dataset \n",
      "\n",
      "Train Epoch: 99 [0/1375 (0%)]\tLoss: 0.210884\n",
      "Accuracy is 97.11305658627087 on train_dataset \n",
      "\n",
      "Train Epoch: 100 [0/1375 (0%)]\tLoss: 0.220104\n",
      "Accuracy is 97.00139146567717 on train_dataset \n",
      "\n",
      "Train Epoch: 101 [0/1375 (0%)]\tLoss: 0.206472\n",
      "Accuracy is 97.16941094619666 on train_dataset \n",
      "\n",
      "Train Epoch: 102 [0/1375 (0%)]\tLoss: 0.218822\n",
      "Accuracy is 96.91465677179963 on train_dataset \n",
      "\n",
      "Train Epoch: 103 [0/1375 (0%)]\tLoss: 0.219549\n",
      "Accuracy is 97.15700371057513 on train_dataset \n",
      "\n",
      "Train Epoch: 104 [0/1375 (0%)]\tLoss: 0.206798\n",
      "Accuracy is 97.38601576994435 on train_dataset \n",
      "\n",
      "Train Epoch: 105 [0/1375 (0%)]\tLoss: 0.216534\n",
      "Accuracy is 97.0761827458256 on train_dataset \n",
      "\n",
      "Train Epoch: 106 [0/1375 (0%)]\tLoss: 0.204866\n",
      "Accuracy is 97.15480055658628 on train_dataset \n",
      "\n",
      "Train Epoch: 107 [0/1375 (0%)]\tLoss: 0.201916\n",
      "Accuracy is 97.10911410018554 on train_dataset \n",
      "\n",
      "Train Epoch: 108 [0/1375 (0%)]\tLoss: 0.191228\n",
      "Accuracy is 97.08151669758813 on train_dataset \n",
      "\n",
      "Train Epoch: 109 [0/1375 (0%)]\tLoss: 0.217517\n",
      "Accuracy is 97.22657699443414 on train_dataset \n",
      "\n",
      "Train Epoch: 110 [0/1375 (0%)]\tLoss: 0.181055\n",
      "Accuracy is 97.13949443413729 on train_dataset \n",
      "\n",
      "Train Epoch: 111 [0/1375 (0%)]\tLoss: 0.203914\n",
      "Accuracy is 97.19712430426716 on train_dataset \n",
      "\n",
      "Train Epoch: 112 [0/1375 (0%)]\tLoss: 0.191987\n",
      "Accuracy is 97.28211966604825 on train_dataset \n",
      "\n",
      "Train Epoch: 113 [0/1375 (0%)]\tLoss: 0.192861\n",
      "Accuracy is 97.09090909090908 on train_dataset \n",
      "\n",
      "Train Epoch: 114 [0/1375 (0%)]\tLoss: 0.188680\n",
      "Accuracy is 97.32908163265304 on train_dataset \n",
      "\n",
      "Train Epoch: 115 [0/1375 (0%)]\tLoss: 0.175259\n",
      "Accuracy is 97.40851113172542 on train_dataset \n",
      "\n",
      "Train Epoch: 116 [0/1375 (0%)]\tLoss: 0.188627\n",
      "Accuracy is 97.44805194805195 on train_dataset \n",
      "\n",
      "Train Epoch: 117 [0/1375 (0%)]\tLoss: 0.180116\n",
      "Accuracy is 97.25220315398887 on train_dataset \n",
      "\n",
      "Train Epoch: 118 [0/1375 (0%)]\tLoss: 0.184720\n",
      "Accuracy is 97.08858998144714 on train_dataset \n",
      "\n",
      "Train Epoch: 119 [0/1375 (0%)]\tLoss: 0.190799\n",
      "Accuracy is 97.3198051948052 on train_dataset \n",
      "\n",
      "Train Epoch: 120 [0/1375 (0%)]\tLoss: 0.183709\n",
      "Accuracy is 97.1463358070501 on train_dataset \n",
      "\n",
      "Train Epoch: 121 [0/1375 (0%)]\tLoss: 0.177654\n",
      "Accuracy is 97.26379870129868 on train_dataset \n",
      "\n",
      "Train Epoch: 122 [0/1375 (0%)]\tLoss: 0.179404\n",
      "Accuracy is 97.51252319109463 on train_dataset \n",
      "\n",
      "Train Epoch: 123 [0/1375 (0%)]\tLoss: 0.183076\n",
      "Accuracy is 97.26762523191096 on train_dataset \n",
      "\n",
      "Train Epoch: 124 [0/1375 (0%)]\tLoss: 0.176471\n",
      "Accuracy is 97.3334879406308 on train_dataset \n",
      "\n",
      "Train Epoch: 125 [0/1375 (0%)]\tLoss: 0.182803\n",
      "Accuracy is 97.33592300556585 on train_dataset \n",
      "\n",
      "Train Epoch: 126 [0/1375 (0%)]\tLoss: 0.172795\n",
      "Accuracy is 97.33545918367348 on train_dataset \n",
      "\n",
      "Train Epoch: 127 [0/1375 (0%)]\tLoss: 0.161022\n",
      "Accuracy is 97.26832096474955 on train_dataset \n",
      "\n",
      "Train Epoch: 128 [0/1375 (0%)]\tLoss: 0.170616\n",
      "Accuracy is 97.53420686456401 on train_dataset \n",
      "\n",
      "Train Epoch: 129 [0/1375 (0%)]\tLoss: 0.174520\n",
      "Accuracy is 97.4448051948052 on train_dataset \n",
      "\n",
      "Train Epoch: 130 [0/1375 (0%)]\tLoss: 0.182166\n",
      "Accuracy is 97.40897495361781 on train_dataset \n",
      "\n",
      "Train Epoch: 131 [0/1375 (0%)]\tLoss: 0.165098\n",
      "Accuracy is 97.37731910946195 on train_dataset \n",
      "\n",
      "Train Epoch: 132 [0/1375 (0%)]\tLoss: 0.152890\n",
      "Accuracy is 97.33000927643783 on train_dataset \n",
      "\n",
      "Train Epoch: 133 [0/1375 (0%)]\tLoss: 0.195680\n",
      "Accuracy is 97.19132653061226 on train_dataset \n",
      "\n",
      "Train Epoch: 134 [0/1375 (0%)]\tLoss: 0.167398\n",
      "Accuracy is 97.14471243042672 on train_dataset \n",
      "\n",
      "Train Epoch: 135 [0/1375 (0%)]\tLoss: 0.168241\n",
      "Accuracy is 97.11328849721707 on train_dataset \n",
      "\n",
      "Train Epoch: 136 [0/1375 (0%)]\tLoss: 0.185911\n",
      "Accuracy is 96.9921150278293 on train_dataset \n",
      "\n",
      "Train Epoch: 137 [0/1375 (0%)]\tLoss: 0.171588\n",
      "Accuracy is 97.32108070500925 on train_dataset \n",
      "\n",
      "Train Epoch: 138 [0/1375 (0%)]\tLoss: 0.174492\n",
      "Accuracy is 97.14192949907236 on train_dataset \n",
      "\n",
      "Train Epoch: 139 [0/1375 (0%)]\tLoss: 0.177177\n",
      "Accuracy is 96.96347402597402 on train_dataset \n",
      "\n",
      "Train Epoch: 140 [0/1375 (0%)]\tLoss: 0.169986\n",
      "Accuracy is 97.07513914656772 on train_dataset \n",
      "\n",
      "Train Epoch: 141 [0/1375 (0%)]\tLoss: 0.161653\n",
      "Accuracy is 97.1876159554731 on train_dataset \n",
      "\n",
      "Train Epoch: 142 [0/1375 (0%)]\tLoss: 0.172148\n",
      "Accuracy is 97.46521335807049 on train_dataset \n",
      "\n",
      "Train Epoch: 143 [0/1375 (0%)]\tLoss: 0.169319\n",
      "Accuracy is 97.39390074211502 on train_dataset \n",
      "\n",
      "Train Epoch: 144 [0/1375 (0%)]\tLoss: 0.147005\n",
      "Accuracy is 97.48805658627087 on train_dataset \n",
      "\n",
      "Train Epoch: 145 [0/1375 (0%)]\tLoss: 0.155741\n",
      "Accuracy is 97.63300092764379 on train_dataset \n",
      "\n",
      "Train Epoch: 146 [0/1375 (0%)]\tLoss: 0.158437\n",
      "Accuracy is 97.4922309833024 on train_dataset \n",
      "\n",
      "Train Epoch: 147 [0/1375 (0%)]\tLoss: 0.150736\n",
      "Accuracy is 97.38601576994435 on train_dataset \n",
      "\n",
      "Train Epoch: 148 [0/1375 (0%)]\tLoss: 0.173042\n",
      "Accuracy is 97.51901669758813 on train_dataset \n",
      "\n",
      "Train Epoch: 149 [0/1375 (0%)]\tLoss: 0.151854\n",
      "Accuracy is 97.62813079777366 on train_dataset \n",
      "\n",
      "Train Epoch: 150 [0/1375 (0%)]\tLoss: 0.153679\n",
      "Accuracy is 97.56922541743971 on train_dataset \n",
      "\n",
      "Train Epoch: 151 [0/1375 (0%)]\tLoss: 0.146116\n",
      "Accuracy is 97.66187384044528 on train_dataset \n",
      "\n",
      "Train Epoch: 152 [0/1375 (0%)]\tLoss: 0.147587\n",
      "Accuracy is 97.62070964749536 on train_dataset \n",
      "\n",
      "Train Epoch: 153 [0/1375 (0%)]\tLoss: 0.152909\n",
      "Accuracy is 97.52887291280149 on train_dataset \n",
      "\n",
      "Train Epoch: 154 [0/1375 (0%)]\tLoss: 0.145680\n",
      "Accuracy is 97.68332560296845 on train_dataset \n",
      "\n",
      "Train Epoch: 155 [0/1375 (0%)]\tLoss: 0.152611\n",
      "Accuracy is 97.79649814471244 on train_dataset \n",
      "\n",
      "Train Epoch: 156 [0/1375 (0%)]\tLoss: 0.142204\n",
      "Accuracy is 97.67138218923932 on train_dataset \n",
      "\n",
      "Train Epoch: 157 [0/1375 (0%)]\tLoss: 0.156731\n",
      "Accuracy is 97.70361781076066 on train_dataset \n",
      "\n",
      "Train Epoch: 158 [0/1375 (0%)]\tLoss: 0.151840\n",
      "Accuracy is 97.81493506493507 on train_dataset \n",
      "\n",
      "Train Epoch: 159 [0/1375 (0%)]\tLoss: 0.147104\n",
      "Accuracy is 97.59925788497218 on train_dataset \n",
      "\n",
      "Train Epoch: 160 [0/1375 (0%)]\tLoss: 0.145756\n",
      "Accuracy is 97.7496521335807 on train_dataset \n",
      "\n",
      "Train Epoch: 161 [0/1375 (0%)]\tLoss: 0.146591\n",
      "Accuracy is 97.8753478664193 on train_dataset \n",
      "\n",
      "Train Epoch: 162 [0/1375 (0%)]\tLoss: 0.143394\n",
      "Accuracy is 97.72924397031541 on train_dataset \n",
      "\n",
      "Train Epoch: 163 [0/1375 (0%)]\tLoss: 0.135006\n",
      "Accuracy is 97.70013914656771 on train_dataset \n",
      "\n",
      "Train Epoch: 164 [0/1375 (0%)]\tLoss: 0.139553\n",
      "Accuracy is 97.73875231910945 on train_dataset \n",
      "\n",
      "Train Epoch: 165 [0/1375 (0%)]\tLoss: 0.128852\n",
      "Accuracy is 97.78061224489795 on train_dataset \n",
      "\n",
      "Train Epoch: 166 [0/1375 (0%)]\tLoss: 0.129991\n",
      "Accuracy is 97.7495361781076 on train_dataset \n",
      "\n",
      "Train Epoch: 167 [0/1375 (0%)]\tLoss: 0.141984\n",
      "Accuracy is 97.75220315398887 on train_dataset \n",
      "\n",
      "Train Epoch: 168 [0/1375 (0%)]\tLoss: 0.137846\n",
      "Accuracy is 97.71811224489795 on train_dataset \n",
      "\n",
      "Train Epoch: 169 [0/1375 (0%)]\tLoss: 0.137066\n",
      "Accuracy is 97.90793135435992 on train_dataset \n",
      "\n",
      "Train Epoch: 170 [0/1375 (0%)]\tLoss: 0.128084\n",
      "Accuracy is 97.79359925788498 on train_dataset \n",
      "\n",
      "Train Epoch: 171 [0/1375 (0%)]\tLoss: 0.145449\n",
      "Accuracy is 97.95779220779221 on train_dataset \n",
      "\n",
      "Train Epoch: 172 [0/1375 (0%)]\tLoss: 0.132923\n",
      "Accuracy is 97.81505102040815 on train_dataset \n",
      "\n",
      "Train Epoch: 173 [0/1375 (0%)]\tLoss: 0.126348\n",
      "Accuracy is 97.78119202226345 on train_dataset \n",
      "\n",
      "Train Epoch: 174 [0/1375 (0%)]\tLoss: 0.121979\n",
      "Accuracy is 97.74315862708721 on train_dataset \n",
      "\n",
      "Train Epoch: 175 [0/1375 (0%)]\tLoss: 0.142049\n",
      "Accuracy is 97.94341372912801 on train_dataset \n",
      "\n",
      "Train Epoch: 176 [0/1375 (0%)]\tLoss: 0.135464\n",
      "Accuracy is 97.73631725417441 on train_dataset \n",
      "\n",
      "Train Epoch: 177 [0/1375 (0%)]\tLoss: 0.137318\n",
      "Accuracy is 97.81145640074212 on train_dataset \n",
      "\n",
      "Train Epoch: 178 [0/1375 (0%)]\tLoss: 0.145634\n",
      "Accuracy is 97.90735157699444 on train_dataset \n",
      "\n",
      "Train Epoch: 179 [0/1375 (0%)]\tLoss: 0.138856\n",
      "Accuracy is 97.82815398886827 on train_dataset \n",
      "\n",
      "Train Epoch: 180 [0/1375 (0%)]\tLoss: 0.134953\n",
      "Accuracy is 97.76136363636364 on train_dataset \n",
      "\n",
      "Train Epoch: 181 [0/1375 (0%)]\tLoss: 0.130970\n",
      "Accuracy is 97.90259740259741 on train_dataset \n",
      "\n",
      "Train Epoch: 182 [0/1375 (0%)]\tLoss: 0.141101\n",
      "Accuracy is 97.77539424860854 on train_dataset \n",
      "\n",
      "Train Epoch: 183 [0/1375 (0%)]\tLoss: 0.115147\n",
      "Accuracy is 97.84334415584415 on train_dataset \n",
      "\n",
      "Train Epoch: 184 [0/1375 (0%)]\tLoss: 0.121027\n",
      "Accuracy is 97.98075139146569 on train_dataset \n",
      "\n",
      "Train Epoch: 185 [0/1375 (0%)]\tLoss: 0.114862\n",
      "Accuracy is 97.8331400742115 on train_dataset \n",
      "\n",
      "Train Epoch: 186 [0/1375 (0%)]\tLoss: 0.140276\n",
      "Accuracy is 97.99628942486085 on train_dataset \n",
      "\n",
      "Train Epoch: 187 [0/1375 (0%)]\tLoss: 0.136583\n",
      "Accuracy is 97.98341836734693 on train_dataset \n",
      "\n",
      "Train Epoch: 188 [0/1375 (0%)]\tLoss: 0.124042\n",
      "Accuracy is 97.88230519480521 on train_dataset \n",
      "\n",
      "Train Epoch: 189 [0/1375 (0%)]\tLoss: 0.117207\n",
      "Accuracy is 97.87847866419295 on train_dataset \n",
      "\n",
      "Train Epoch: 190 [0/1375 (0%)]\tLoss: 0.120872\n",
      "Accuracy is 98.10099721706865 on train_dataset \n",
      "\n",
      "Train Epoch: 191 [0/1375 (0%)]\tLoss: 0.131408\n",
      "Accuracy is 97.96532931354359 on train_dataset \n",
      "\n",
      "Train Epoch: 192 [0/1375 (0%)]\tLoss: 0.119341\n",
      "Accuracy is 98.01055194805194 on train_dataset \n",
      "\n",
      "Train Epoch: 193 [0/1375 (0%)]\tLoss: 0.119604\n",
      "Accuracy is 98.12233302411873 on train_dataset \n",
      "\n",
      "Train Epoch: 194 [0/1375 (0%)]\tLoss: 0.117976\n",
      "Accuracy is 98.00718923933208 on train_dataset \n",
      "\n",
      "Train Epoch: 195 [0/1375 (0%)]\tLoss: 0.112114\n",
      "Accuracy is 97.9442254174397 on train_dataset \n",
      "\n",
      "Train Epoch: 196 [0/1375 (0%)]\tLoss: 0.133305\n",
      "Accuracy is 97.99350649350647 on train_dataset \n",
      "\n",
      "Train Epoch: 197 [0/1375 (0%)]\tLoss: 0.133958\n",
      "Accuracy is 97.97472170686457 on train_dataset \n",
      "\n",
      "Train Epoch: 198 [0/1375 (0%)]\tLoss: 0.115533\n",
      "Accuracy is 97.96776437847868 on train_dataset \n",
      "\n",
      "Train Epoch: 199 [0/1375 (0%)]\tLoss: 0.105677\n",
      "Accuracy is 98.01913265306122 on train_dataset \n",
      "\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"amt\")\n",
    "cnn_model = CNN().to(device)#ANN(257,nn.SELU(),107).to(device)\n",
    "cnn_model.conv1.apply(init_weights)\n",
    "cnn_model.fc1.apply(init_weights)\n",
    "wandb.watch(cnn_model)\n",
    "new_optimizer = optim.Adam(cnn_model.parameters(),lr=0.001)\n",
    "epoch_num = 200\n",
    "log_interval = 200\n",
    "losses = []\n",
    "pos_weight = torch.Tensor([20]*88).to(device)\n",
    "loss_function = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "for epoch in range(epoch_num):\n",
    "    avg_epoch_loss = 0\n",
    "    cnn_model.train()\n",
    "    accuracy = 0\n",
    "    correct = np.zeros(88)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        labels = target\n",
    "        target =  labels.clone().detach().squeeze().to(device)\n",
    "        new_optimizer.zero_grad()\n",
    "        output = cnn_model(data.float())\n",
    "        \n",
    "        loss = loss_function(output.float(), target.float())\n",
    "        avg_epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        new_optimizer.step()\n",
    "\n",
    "        cur_accuracy = calculate_avg_accuracy(torch.round(torch.sigmoid(output)), target)\n",
    "        correct = np.add(correct,cur_accuracy)\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "            losses.append(loss.item())\n",
    "    \n",
    "    avg_epoch_loss /= len(train_loader)\n",
    "    f1_train_micro,sklearn_train_acc, train_prec, train_rec = calc_f_score(cnn_model,device,train_loader,y_train,0.5)\n",
    "    f1_test_micro,_, _,_ = calc_f_score(cnn_model,device,test_loader,y_test,0.5)\n",
    "    f1_test_macro, sklearn_acc, test_prec,test_rec = calc_f_score(cnn_model,device,test_loader,y_test,0.5,'macro')\n",
    "    f1_test_samples, _, _,_ = calc_f_score(cnn_model,device,test_loader,y_test,0.5,'samples')\n",
    "    wandb.log({\"Average batch loss\": avg_epoch_loss, \"Test F1 Micro Score\": f1_test_micro, \n",
    "               \"Test F1 Macro Score\": f1_test_macro, \"Test F1 Samples Score\": f1_test_samples, 'Train F1 Micro Score' : f1_train_micro,\n",
    "               \"Sklearn_test_accuracy\" : sklearn_acc,\"Sklearn_train_accuracy\" : sklearn_train_acc, 'Train Precsion': train_prec,\n",
    "               \"Train Recall\": train_rec, \"Test Precision\": test_prec, \"Test Recall\": test_rec})\n",
    "    correct /= len(train_loader)\n",
    "    accuracy = np.mean(correct)\n",
    "    train_accuracy = 100. * accuracy\n",
    "   \n",
    "    #test_accuracy = test(model,device,test_loader)\n",
    "    print('Accuracy is {} on train_dataset'.format(train_accuracy), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions,probs = eval(model,device,test_loader,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_prediction = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_class = [x[0] for x in probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_class = [x[0].numpy() for x in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(true_class, probs_class,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a434a35ba8>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(thresholds, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a43480a1d0>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(thresholds, fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a443736208>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8558823529411764"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_score = auc(fpr,tpr)\n",
    "auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class = [x[22] for x in predictions]\n",
    "true_class = [x[22] for x in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive,false_positive,false_negative, true_negative = [0]*len(predictions[0]),[0]*len(predictions[0]),[0]*len(predictions[0]),[0]*len(predictions[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
